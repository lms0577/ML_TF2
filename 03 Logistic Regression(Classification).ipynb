{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression(Binary Classification) - Eager Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Data\n",
    "* x_data가 2차원 배열이기에 2차원 공간에 표현하여 x1과 x2를 기준으로 y_data 0과 1로 구분하는 예제입니다\n",
    "* Logistic Classification 통해 보라색과 노란색 y_data(Label)을 구분해 보겠습니다.\n",
    "* Test 데이터는 붉은색의 위치와 같이 추론시 1의 값을 가지게 됩니다.\n",
    "\n",
    "x1 | x2 | Y\n",
    "---- | ---- | ----\n",
    "1 | 2 | 0\n",
    "2 | 3 | 0 \n",
    "3 | 1 | 0\n",
    "4 | 3 | 1\n",
    "5 | 3 | 1\n",
    "6 | 2 | 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAW2klEQVR4nO3df7DddZ3f8eeLJFYIqLvkLmshGNva7qorP/YadWQV3BFDq6VObQfGIrU6mTpYsbW7VdzKiHWnrFPqj6o0hQhqILpCkK78yqxUZKnIDUWBRHcziJIMbi4ECSGG5Oa++8f5Bg7J9yY3cL/3JPc+HzNnzjmfz+f7Pe/vDOR1P9/v95xPqgpJkvZ02KALkCQdnAwISVIrA0KS1MqAkCS1MiAkSa3mDrqAqbRgwYJatGjRoMuQpEPGmjVrHqmqoba+GRUQixYtYmRkZNBlSNIhI8nPJ+rzFJMkqZUBIUlqZUBIkloZEJKkVgbELPXIxkfxd7hmtqqidv1y0GVMq6pxatffDrqMGaOzgEjywiQ/TPKjJPcn+WTLmL+T5BtJ1ie5M8mivr6PNe0/TfK2ruqcjR5/ZAvn/sMP8d2rbh90KerSjtup0dOosQ2DrmTa1LaV1CNnUONbB13KjNDlDOIp4C1VdQJwIrAkyev3GPM+4LGq+gfAfwcuBkjySuAs4FXAEuBLSeZ0WOussvLi6xjbMcZlH/06u3btGnQ56kBVUVv+KzBObf38oMuZFlU7YOtnobZT27466HJmhM4Conp2x/i85rHnOY0zgSub198C/jBJmvaVVfVUVf0MWA8s7qrW2eTxR7bwv790M+O7xtn6+Da+9407Bl2SurDjdhjfCBRsv5HatXHQFXWutn0L2AGMwZPLnEVMgU6vQSSZk+QeYBOwuqru3GPIscBDAFU1BjwOHN3f3tjQtLV9xtIkI0lGRkdHp/gIZp6VF1/39LWH7Vu387/+k7OImebp2UNta1p2UU98bqA1de2Z2UNzzDXuLGIKdBoQVbWrqk4EjgMWJ3l1B5+xrKqGq2p4aKj12+Jq7J497Ni+8+k2ZxEz0NOzh93GZvws4pnZw27bnUVMgWm5i6mqfgXcSu96Qr+NwEKAJHOBFwOP9rc3jmva9DysvPg6xnY+e7bgLGJm2Xv2sNvYjJ1F7DV7eLpjp7OI56mz32JKMgTsrKpfJTkceCvNReg+1wPnAv8XeBfw3aqqJNcDVyW5BPi7wCuAH3ZV62xR48XLf+/4vdoPP+pwtj/5FPNfdMQAqtLU2gWHHQ2Zt3dXZtRPrz1j/AmY+/egtu/dVzv2btOkdflfzEuBK5u7jw4DvllVf5HkImCkqq4HLge+lmQ9sJnenUtU1f1JvgmsBcaA86rKP3Gfp3/7384ddAnqWDKXHD27/mrOnKPJ0SsHXcaMlJn0Zanh4eHy11wlafKSrKmq4bY+v0ktSWplQEiSWhkQkqRWBoQkqZUBIUlqZUBIkloZEJKkVgaEJKmVASFJamVASJJaGRCSpFYGhCSplQEhSWplQEiSWhkQkqRWBoQkqVWXS44uBL4KHAMUsKyqPrfHmD8C3t1Xy+8CQ1W1OcmDwBPALmBsogUtJEnd6HLJ0THgI1V1d5KjgDVJVlfV2t0DquozwGcAkrwD+PdVtblvH6dV1SMd1ihJmkBnp5iq6uGqurt5/QSwDjh2H5ucDVzdVT2SpAMzLdcgkiwCTgLunKD/CGAJcE1fcwG3JFmTZOk+9r00yUiSkdHR0SmsWpJmt84DIsmR9P7h/3BVbZlg2DuAv9rj9NIpVXUycAZwXpI3tW1YVcuqariqhoeGhqa0dkmazToNiCTz6IXDiqq6dh9Dz2KP00tVtbF53gSsAhZ3VackaW+dBUSSAJcD66rqkn2MezHwZuDbfW3zmwvbJJkPnA7c11WtkqS9dXkX0xuBc4B7k9zTtF0AHA9QVZc2be8EbqmqJ/u2PQZY1csY5gJXVdVNHdYqSdpDZwFRVbcDmcS4K4Ar9mh7ADihk8IkSZPiN6klSa0MCElSKwNCktTKgJAktTIgJEmtDAhJUisDQpLUyoCQJLUyICRJrQwISVIrA0KS1MqAkCS1MiAkSa0MCElSKwNCktTKgJAktepyydGFSW5NsjbJ/UnObxlzapLHk9zTPD7R17ckyU+TrE/y0a7qlCS163LJ0THgI1V1d7O+9Jokq6tq7R7jvl9Vb+9vSDIH+CLwVmADcFeS61u2lSR1pLMZRFU9XFV3N6+fANYBx05y88XA+qp6oKp2ACuBM7upVJLUZlquQSRZBJwE3NnS/YYkP0pyY5JXNW3HAg/1jdnABOGSZGmSkSQjo6OjU1m2JM1qnQdEkiOBa4APV9WWPbrvBl5WVScAXwCuO9D9V9WyqhququGhoaHnXa8kqafTgEgyj144rKiqa/fsr6otVbW1eX0DMC/JAmAjsLBv6HFNmyRpmnR5F1OAy4F1VXXJBGN+uxlHksVNPY8CdwGvSPLyJC8AzgKu76pWSdLeuryL6Y3AOcC9Se5p2i4AjgeoqkuBdwEfSDIG/Bo4q6oKGEvyQeBmYA6wvKru77BWSdIe0vv3eGYYHh6ukZGRQZchSYeMJGuqaritz29SS5JaGRCSpFYGhCSplQEhSWplQEiSWhkQkqRWBoQkqZUBIUlqZUBIkloZEJKkVgaEJKmVASFJamVASJJaGRCSpFYGhCSpVZcryi1McmuStUnuT3J+y5h3J/lxknuT3JHkhL6+B5v2e5K4yIMkTbMuV5QbAz5SVXcnOQpYk2R1Va3tG/Mz4M1V9ViSM4BlwOv6+k+rqkc6rFGSNIHOAqKqHgYebl4/kWQdcCywtm/MHX2b/AA4rqt6JEkHZlquQSRZBJwE3LmPYe8Dbux7X8AtSdYkWbqPfS9NMpJkZHR0dErqlSR1e4oJgCRHAtcAH66qLROMOY1eQJzS13xKVW1M8lvA6iQ/qarb9ty2qpbROzXF8PDwzFlgW5IGrNMZRJJ59MJhRVVdO8GY1wCXAWdW1aO726tqY/O8CVgFLO6yVknSs3V5F1OAy4F1VXXJBGOOB64Fzqmqv+5rn99c2CbJfOB04L6uapUk7a3LU0xvBM4B7k1yT9N2AXA8QFVdCnwCOBr4Ui9PGKuqYeAYYFXTNhe4qqpu6rBWSdIeuryL6XYg+xnzfuD9Le0PACfsvYUkabr4TWpJUisDQpLUyoCQJLUyICRJrQwISVIrA0KS1MqAkCS1MiAkSa0MCElSKwNCktTKgJAktTIgJEmtDAhJUisDQpLUyoCQJLUyIICf3rWeJx9/ctBlSNIBq/HHqJ1rO9n3PgMiyYuS/P2W9tfsb8dJFia5NcnaJPcnOb9lTJJ8Psn6JD9OcnJf37lJ/qZ5nDvZAzpQT27Zxn98yye57KMruvoISdNhxQpYtAgOO6z3vGJ2/D9dWz5FbX4PVU9N+b4nDIgk/xL4CXBN8w/8a/u6r5jEvseAj1TVK4HXA+cleeUeY84AXtE8lgJfbj77N4ELgdcBi4ELk/zGpI7oAF37ue+wa2wXt1z5f3j04ce6+AhJXVuxApYuhZ//HKp6z0uXzviQqLFfwPbVUDuobSunfP/7mkFcAPx+VZ0IvBf4WpJ3Nn37XEoUoKoerqq7m9dPAOuAY/cYdibw1er5AfCSJC8F3gasrqrNVfUYsBpYcgDHNSlPbtnGn3/menY+tZPx8eLrF/35VH+EpOnw8Y/Dtm3Pbtu2rdc+g9XWz9L7W3w7bP3ClM8i9hUQc6rqYYCq+iFwGvAnST4E1IF8SJJFwEnAnXt0HQs81Pd+Q9M2UXvbvpcmGUkyMjo6eiBlce3nvsP4+DgAYzvGnEVIh6pf/OLA2meAp2cP7Goadk75LGJfAfFE//WHJixOpfdX/6sm+wFJjgSuAT5cVVueY50TqqplVTVcVcNDQ0OT3m737OGpbTuebnMWIR2ijj/+wNpngGdmD7v9espnEfsKiA8Ah/VfN2hOFS0B3j+ZnSeZRy8cVlTVtS1DNgIL+94f17RN1D5lVn3+BnZs3/GstrEdY9xw2V+y+ZfOIqRDyqc/DUcc8ey2I47otc9ANfYQbP8OT88enu54ktr2jSn7nLkTFlD1I4Ak9yX5GvBnwAub52Hga/vacZIAlwPrquqSCYZdD3wwyUp6F6Qfr6qHk9wM/GnfhenTgY9N/rD2b+HvHMtb33PqXu1z582Zyo+RNB3e/e7e88c/3jutdPzxvXDY3T7TZA4c/i+A8b375hw3dR9Tte/LCUnmAxcDvw8cBawALq6qlsqetd0pwPeBe3nmKC4AjgeoqkubEPkf9GYl24D3VtVIs/2/acYDfLqqvrK/gxkeHq6RkZH9DZMkNZKsqarhtr4JZxB9dgK/Bg6nN4P42f7CAaCqbmc/dztVL53Om6BvObB8EvVJkjowmW9S30UvIF4L/AFwdhKv5ErSDDeZGcT7dp/2AR4GzkxyToc1SZIOAvudQfSFQ3/bPi9QS5IOff5YnySplQEhSWplQEiSWhkQkqRWBoQkqZUBIUlqZUBIkloZEJKkVgaEJKmVASFJamVASJJaGRCSpFYGhCSp1WR+7vs5SbIceDuwqape3dL/R8Du9QDnAr8LDFXV5iQPAk/QW3B1bKLVjiRJ3elyBnEFvaVEW1XVZ6rqxKo6kd5609+rqs19Q05r+g0HSRqAzgKiqm4DNu93YM/ZwNVd1SJJOnADvwaR5Ah6M41r+poLuCXJmiRL97P90iQjSUZGR0e7LFWSZpWBBwTwDuCv9ji9dEpVnQycAZyX5E0TbVxVy6pquKqGh4aGuq5VkmaNgyEgzmKP00tVtbF53gSsAhYPoC5JmtUGGhBJXgy8Gfh2X9v8JEftfg2cDtw3mAolafbq8jbXq4FTgQVJNgAXAvMAqurSZtg7gVuq6sm+TY8BViXZXd9VVXVTV3VKktp1FhBVdfYkxlxB73bY/rYHgBO6qUqSNFkHwzUISdJByICQJLUyICRJrQwISVIrA0KS1MqAkCS1MiAkSa0MCElSKwNCktTKgJAktTIgJEmtDAhJUisDQpLUyoCQJLUyICRJrToLiCTLk2xK0roaXJJTkzye5J7m8Ym+viVJfppkfZKPdlWjJGliXc4grgCW7GfM96vqxOZxEUCSOcAXgTOAVwJnJ3llh3VKklp0FhBVdRuw+TlsuhhYX1UPVNUOYCVw5pQWJ0nar0Ffg3hDkh8luTHJq5q2Y4GH+sZsaNpaJVmaZCTJyOjoaJe1StKsMsiAuBt4WVWdAHwBuO657KSqllXVcFUNDw0NTWV9kjSrDSwgqmpLVW1tXt8AzEuyANgILOwbelzTJkmaRgMLiCS/nSTN68VNLY8CdwGvSPLyJC8AzgKuH1SdkjRbze1qx0muBk4FFiTZAFwIzAOoqkuBdwEfSDIG/Bo4q6oKGEvyQeBmYA6wvKru76pOSVK79P5NnhmGh4drZGRk0GVI0iEjyZqqGm7rG/RdTJKkg5QBIUlqZUBIkloZEJKkVgaEJKmVASFJamVASJJaGRCSpFYGhCSplQEhSWplQEiSWhkQkqRWBoQkqZUBIUlqZUBIkloZEJKkVp0FRJLlSTYluW+C/ncn+XGSe5PckeSEvr4Hm/Z7krgCkCQNQJcziCuAJfvo/xnw5qr6PeBTwLI9+k+rqhMnWulIktStztakrqrbkizaR/8dfW9/ABzXVS2SpAN3sFyDeB9wY9/7Am5JsibJ0n1tmGRpkpEkI6Ojo50WKUmzSWcziMlKchq9gDilr/mUqtqY5LeA1Ul+UlW3tW1fVctoTk8NDw9X5wVL0iwx0BlEktcAlwFnVtWju9uramPzvAlYBSweTIWSNHsNLCCSHA9cC5xTVX/d1z4/yVG7XwOnA613QkmSutPZKaYkVwOnAguSbAAuBOYBVNWlwCeAo4EvJQEYa+5YOgZY1bTNBa6qqpu6qlOS1K7Lu5jO3k//+4H3t7Q/AJyw9xaSpOl0sNzFJEk6yBgQkqRWBoQkqZUBIUlqZUBIkloZEJKkVgaEJKmVASFJamVASJJaGRCSpFYGhCSplQEhSWplQEiSWhkQkqRWBoQkqZUBoVlhfHyc675wI2M7xwZdinTI6DQgkixPsilJ65Kh6fl8kvVJfpzk5L6+c5P8TfM4t8s6NfPd8e27+OL5y7nlyu8NuhTpkNH1DOIKYMk++s8AXtE8lgJfBkjym/SWKH0dsBi4MMlvdFqpZqzx8XGW/fHXAPjKx69yFiFNUqcBUVW3AZv3MeRM4KvV8wPgJUleCrwNWF1Vm6vqMWA1+w4aaUJ3fPsuHvvbxwHY/usdziKkSRr0NYhjgYf63m9o2iZq30uSpUlGkoyMjo52VqgOTbtnD9u3bgdg+9btziKkSRp0QDxvVbWsqoaranhoaGjQ5egg0z972M1ZhDQ5gw6IjcDCvvfHNW0TtUsH5Ct/cjU7t+/gBS+c9/Rj51M7ufITKwddmnTQmzvgz78e+GCSlfQuSD9eVQ8nuRn4074L06cDHxtUkTp0/euLzmLzL3+1V/uRL5k//cVIh5hOAyLJ1cCpwIIkG+jdmTQPoKouBW4A/jGwHtgGvLfp25zkU8Bdza4uqqp9XeyWWv3BP3/9oEuQDlmdBkRVnb2f/gLOm6BvObC8i7okSfs36GsQkqSDlAEhSWplQEiSWhkQkqRW6V0nnhmSjAI/f46bLwAemcJyDgUe88w3244XPOYD9bKqav2W8YwKiOcjyUhVDQ+6junkMc98s+14wWOeSp5ikiS1MiAkSa0MiGcsG3QBA+Axz3yz7XjBY54yXoOQJLVyBiFJamVASJJazfqASLI8yaYk9w26lumQZGGSW5OsTXJ/kvMHXVPXkrwwyQ+T/Kg55k8OuqbpkmROkv+X5C8GXct0SPJgknuT3JNkZND1TIckL0nyrSQ/SbIuyRumbN+z/RpEkjcBW+mtjf3qQdfTtWbN75dW1d1JjgLWAP+sqtYOuLTOJAkwv6q2JpkH3A6c36yDPqMl+Q/AMPCiqnr7oOvpWpIHgeGqmjVflEtyJfD9qrosyQuAI6rqV1Ox71k/g6iq24BZs9ZEVT1cVXc3r58A1jHBet8zRfVsbd7Oax4z/i+jJMcB/wS4bNC1qBtJXgy8CbgcoKp2TFU4gAExqyVZBJwE3DngUjrXnGq5B9gErK6qGX/MwGeBPwbGB1zHdCrgliRrkiwddDHT4OXAKPCV5lTiZUmmbLlEA2KWSnIkcA3w4araMuh6ulZVu6rqRHrrmy9OMqNPJyZ5O7CpqtYMupZpdkpVnQycAZzXnEKeyeYCJwNfrqqTgCeBj07Vzg2IWag5D38NsKKqrh10PdOpmX7fCiwZcCldeyPwT5tz8iuBtyT5+mBL6l5VbWyeNwGrgMWDrahzG4ANfTPib9ELjClhQMwyzQXby4F1VXXJoOuZDkmGkrykeX048FbgJwMtqmNV9bGqOq6qFgFnAd+tqn814LI6lWR+c+MFzWmW04EZfXdiVf0SeCjJP2qa/hCYshtOOl2T+lCQ5GrgVGBBkg3AhVV1+WCr6tQbgXOAe5tz8gAXVNUNgyupcy8Frkwyh94fRd+sqllx2+cscwywqvc3EHOBq6rqpsGWNC3+HbCiuYPpAeC9U7XjWX+bqySpnaeYJEmtDAhJUisDQpLUyoCQJLUyICRJrQwIaRokuSnJr2bLr6pqZjAgpOnxGXrfP5EOGQaENIWSvDbJj5s1KOY360+8uqr+Enhi0PVJB2LWf5NamkpVdVeS64H/AhwOfL2qZvTPPWjmMiCkqXcRcBewHfjQgGuRnjNPMUlT72jgSOAo4IUDrkV6zgwIaer9T+A/AyuAiwdci/SceYpJmkJJ3gPsrKqrml+PvSPJW4BPAr8DHNn8avD7qurmQdYq7Y+/5ipJauUpJklSKwNCktTKgJAktTIgJEmtDAhJUisDQpLUyoCQJLX6/4NSpyZmabb7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = np.array([\n",
    "    # X1,  X2,  y\n",
    "    [ 1.,  2.,  0. ],\n",
    "    [ 2.,  3.,  0. ],\n",
    "    [ 3.,  1.,  0. ],\n",
    "    [ 4.,  3.,  1. ],\n",
    "    [ 5.,  3.,  1. ],\n",
    "    [ 6.,  2.,  1. ]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# slice data\n",
    "# train data\n",
    "x_train = data[:, :-1] # 6행 2열\n",
    "y_train = data[:, [-1]] # 6행 1열(마지막 열)\n",
    "\n",
    "# test data\n",
    "x_test = [[5.,2.]]\n",
    "y_test = [[1.]]\n",
    "\n",
    "x1 = [x[0] for x in x_train]\n",
    "x2 = [x[1] for x in x_train]\n",
    "\n",
    "colors = [int(y[0] % 3) for y in y_train]\n",
    "plt.scatter(x1,x2, c=colors , marker='^')\n",
    "plt.scatter(x_test[0][0],x_test[0][1], c=\"red\")\n",
    "\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Tensorflow Eager\n",
    "### 위 Data를 기준으로 가설의 검증을 통해 Logistic Classification 모델을 만들도록 하겠습니다\n",
    "* Tensorflow data API를 통해 학습시킬 값들을 담는다 (Batch Size는 한번에 학습시킬 Size로 정한다)\n",
    "* features,labels는 실재 학습에 쓰일 Data (연산을 위해 Type를 맞춰준다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((None, 2), (None, 1)), types: (tf.float32, tf.float32)>\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(len(x_train))#.repeat()\n",
    "print(datast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 위 Data를 기준으로 가설의 검증을 통해 Logistic Classification 모델을 만들도록 하겠습니다\n",
    "* W와 b은 학습을 통해 생성되는 모델에 쓰이는 Wegith와 Bias (초기값을 variable : 0이나 Random값으로 가능 tf.random_normal([2, 1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)  # for reproducibility\n",
    "\n",
    "# 0의 값으로 변수 설정\n",
    "W = tf.Variable(tf.zeros([2,1]), name='weight')\n",
    "b = tf.Variable(tf.zeros([1]), name='bias') \n",
    "# 임의의 값으로 변수 설정\n",
    "#W = tf.Variable(tf.random.normal((2, 1))) # 2행 1열\n",
    "#b = tf.Variable(tf.random.normal((1,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Hypothesis using matrix(가설 or 모델)\n",
    "### Sigmoid 함수를 가설로 선언합니다\n",
    "* Sigmoid는 아래 그래프와 같이 0과 1의 값만을 리턴합니다 tf.sigmoid(tf.matmul(X, W) + b)와 같습니다\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "sigmoid(x) & = \\frac{1}{1+e^{-x}}  \\\\\\\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "![sigmoid](https://upload.wikimedia.org/wikipedia/commons/8/88/Logistic-curve.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가설\n",
    "def logistic_regression(features):\n",
    "    hypothesis  = tf.sigmoid(tf.matmul(features, W) + b)\n",
    "    return hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Cost Function (손실 함수)\n",
    "$$\n",
    "\\begin{align}\n",
    "cost(h(x),y) & = −log(h(x))  &  if  &  y=1 \\\\\\\\\\\n",
    "cost(h(x),y) & = -log(1−h(x))  &  if  &  y=0\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "* 위 두수식을 합치면 아래과 같습니다\n",
    "$$\n",
    "\\begin{align}\n",
    "cost(h(x),y) & = −y log(h(x))−(1−y)log(1−h(x))\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(hypothesis, features, labels):\n",
    "    cost = -tf.reduce_mean(labels * tf.math.log(logistic_regression(features)) + (1 - labels) * tf.math.log(1 - hypothesis))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Optimizer (Minimize Cost Function)\n",
    "### Gradient descent\n",
    "$$ W := W-\\alpha \\frac { \\partial  }{ \\partial W } cost(W) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경사 하강법\n",
    "# tf.GradientTape() 사용\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "def grad(features, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss_fn(logistic_regression(features),features,labels)\n",
    "    return tape.gradient(loss_value, [W,b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추론한 값은 0.5를 기준(Sigmoid 그래프 참조)로 0과 1의 값을 리턴합니다.\n",
    "* Sigmoid 함수를 통해 예측값이 0.5보다 크면 1을 반환하고 0.5보다 작으면 0으로 반환합니다.\n",
    "* 가설을 통해 실재 값과 비교한 정확도를 측정합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(hypothesis, labels):\n",
    "    predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, labels), dtype=tf.int32))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0, Loss: 0.6821\n",
      "Iter: 100, Loss: 0.5770\n",
      "Iter: 200, Loss: 0.5345\n",
      "Iter: 300, Loss: 0.5052\n",
      "Iter: 400, Loss: 0.4836\n",
      "Iter: 500, Loss: 0.4670\n",
      "Iter: 600, Loss: 0.4534\n",
      "Iter: 700, Loss: 0.4419\n",
      "Iter: 800, Loss: 0.4318\n",
      "Iter: 900, Loss: 0.4227\n",
      "Iter: 1000, Loss: 0.4143\n"
     ]
    }
   ],
   "source": [
    "# 훈련 반복 횟수 설정\n",
    "epoch = 1000\n",
    "for step in range(epoch + 1):\n",
    "    for features, labels  in iter(dataset):\n",
    "        grads = grad(features, labels)\n",
    "        optimizer.apply_gradients(grads_and_vars=zip(grads,[W,b]))\n",
    "        if step % 100 == 0:\n",
    "            print(\"Iter: {}, Loss: {:.4f}\".format(step, loss_fn(logistic_regression(features),features,labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict (예측)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train # labels, 실제값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21676369],\n",
       "       [0.26433405],\n",
       "       [0.68672633],\n",
       "       [0.6295152 ],\n",
       "       [0.7870086 ],\n",
       "       [0.9308373 ]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression(x_train).numpy() # prediction, 예측값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testset Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터에 대한 예측\n",
    "test_acc = accuracy_fn(logistic_regression(x_test),y_test)\n",
    "print(\"Testset Accuracy: {:.4f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
