{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-variable Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Data\n",
    "Predicting exam score - regression using three inputs (x1, x2, x3)\n",
    "\n",
    "x1 (quiz 1) | x2 (quiz 2) | x3 (mid 1) | Y (final)\n",
    "---- | ---- | ----| ----\n",
    "73 | 80 | 75 | 152\n",
    "93 | 88 | 93 | 185\n",
    "89 | 91 | 90 | 180\n",
    "96 | 98 | 100 | 196\n",
    "73 | 66 | 70 | 142\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([\n",
    "    # X1,   X2,    X3,   y\n",
    "    [ 73.,  80.,  75., 152. ],\n",
    "    [ 93.,  88.,  93., 185. ],\n",
    "    [ 89.,  91.,  90., 180. ],\n",
    "    [ 96.,  98., 100., 196. ],\n",
    "    [ 73.,  66.,  70., 142. ]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# slice data\n",
    "X = data[:, :-1] # 5행 3열\n",
    "y = data[:, [-1]] # 5행 1열(마지막 열)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Hypothesis using matrix(가설 or 모델)\n",
    "### Many x instances\n",
    "\n",
    "$$ \\begin{pmatrix} x_{ 11 } & x_{ 12 } & x_{ 13 } \\\\ x_{ 21 } & x_{ 22 } & x_{ 23 } \\\\ x_{ 31 } & x_{ 32 } & x_{ 33 }\\\\ x_{ 41 } & x_{ 42 } & x_{ 43 }\\\\ x_{ 51 } & x_{ 52 } & x_{ 53 }\\end{pmatrix} \\cdot \\begin{pmatrix} w_{ 1 } \\\\ w_{ 2 } \\\\ w_{ 3 } \\end{pmatrix} + b=\\begin{pmatrix} x_{ 11 }w_{ 1 }+x_{ 12 }w_{ 2 }+x_{ 13 }w_{ 3 } \\\\ x_{ 21 }w_{ 1 }+x_{ 22 }w_{ 2 }+x_{ 23 }w_{ 3 }\\\\ x_{ 31 }w_{ 1 }+x_{ 32 }w_{ 2 }+x_{ 33 }w_{ 3 } \\\\ x_{ 41 }w_{ 1 }+x_{ 42 }w_{ 2 }+x_{ 43 }w_{ 3 } \\\\ x_{ 51 }w_{ 1 }+x_{ 52 }w_{ 2 }+x_{ 53 }w_{ 3 } \\end{pmatrix} + b$$\n",
    "\n",
    "$$ [5, 3] \\cdot [3, 1] = [5, 1] $$\n",
    "\n",
    "$$ H(X) = XW + b$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)  # for reproducibility\n",
    "\n",
    "# 임의의 값으로 변수 설정\n",
    "W = tf.Variable(tf.random.normal((3, 1))) # 3행 1열\n",
    "b = tf.Variable(tf.random.normal((1,)))\n",
    "\n",
    "# 가설\n",
    "# hypothesis, prediction function\n",
    "def predict(X):\n",
    "    return tf.matmul(X, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Cost Function (손실 함수)\n",
    "$$ cost(W, b)=\\frac { 1 }{ m } \\sum _{i=1}^{m}{ { (H{ x }^{ i }-y^{ i } })^{ 2 } }  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.reduce_mean(): 평균\n",
    "# tf.square(a): a^2\n",
    "cost = tf.reduce_mean((tf.square(predict(X) - y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Optimizer (Minimize Cost Function)\n",
    "### Gradient descent\n",
    "$$ W := W-\\alpha \\frac { \\partial  }{ \\partial W } cost(W) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경사 하강법\n",
    "# tf.GradientTape() 사용\n",
    "learning_rate = 0.000001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 |  1798.2894\n",
      "  100 |     2.2888\n",
      "  200 |     2.0632\n",
      "  300 |     2.0587\n",
      "  400 |     2.0542\n",
      "  500 |     2.0498\n",
      "  600 |     2.0453\n",
      "  700 |     2.0409\n",
      "  800 |     2.0366\n",
      "  900 |     2.0322\n",
      " 1000 |     2.0279\n",
      " 1100 |     2.0236\n",
      " 1200 |     2.0194\n",
      " 1300 |     2.0151\n",
      " 1400 |     2.0108\n",
      " 1500 |     2.0066\n",
      " 1600 |     2.0024\n",
      " 1700 |     1.9982\n",
      " 1800 |     1.9940\n",
      " 1900 |     1.9899\n",
      " 2000 |     1.9857\n"
     ]
    }
   ],
   "source": [
    "# 훈련 반복 횟수 설정\n",
    "epoch = 2000\n",
    "for i in range(epoch + 1):\n",
    "    # Gradient descent (경사하강법)\n",
    "    # tf.GradientTape() to record the gradient of the cost function\n",
    "    with tf.GradientTape() as tape:\n",
    "        cost = tf.reduce_mean((tf.square(predict(X) - y)))\n",
    "        \n",
    "    # 경사하강법으로 w, b의 기울기 값(미분)을 얻는다.\n",
    "    # calculates the gradients of the loss\n",
    "    W_grad, b_grad = tape.gradient(cost, [W, b])\n",
    "    \n",
    "    # w, b의 값을 업데이트\n",
    "    # a.assign_sub(b): a = a - b\n",
    "    W.assign_sub(learning_rate * W_grad)\n",
    "    b.assign_sub(learning_rate * b_grad)\n",
    "    \n",
    "    # 100번에 한번 값 출력\n",
    "    if i % 100 == 0:\n",
    "        print(\"{:5} | {:10.4f}\".format(i, cost.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict (예측)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[152.],\n",
       "       [185.],\n",
       "       [180.],\n",
       "       [196.],\n",
       "       [142.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y # labels, 실제값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[151.39648],\n",
       "       [184.93794],\n",
       "       [180.81708],\n",
       "       [194.1263 ],\n",
       "       [144.31987]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(X).numpy() # prediction, 예측값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[182.69525],\n",
       "       [174.3433 ]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 새로운 데이터에 대한 예측\n",
    "\n",
    "predict([[ 89.,  95.,  92.],[ 84.,  92.,  85.]]).numpy() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
