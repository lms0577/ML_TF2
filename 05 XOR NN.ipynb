{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOR Neural Network - Eager Execution\n",
    "* XOR 문제를 Neural Network을 활용해 풀어보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Data\n",
    "* XOR 문제를 해결하기 위한 트레이닝 데이터\n",
    "* XOR은 데이터의 값이 같으면 0, 다르면 1을 나타낸다.\n",
    "\n",
    "x1 | x2 | Y\n",
    "---- | ---- | ----\n",
    "0 | 0 | 0\n",
    "0 | 1 | 1 \n",
    "1 | 0 | 1\n",
    "1 | 1 | 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = np.array([\n",
    "    # X1,  X2,  y\n",
    "    [ 0.,  0.,  0. ],\n",
    "    [ 0.,  1.,  1. ],\n",
    "    [ 1.,  0.,  1. ],\n",
    "    [ 1.,  1.,  0. ]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# slice data\n",
    "# train data\n",
    "x_train = data[:, :-1] # 4행 2열\n",
    "y_train = data[:, [-1]] # 4행 1열(마지막 열)\n",
    "\n",
    "# test data\n",
    "x_test = [[2.,2.]]\n",
    "y_test = [[0.]]\n",
    "\n",
    "x1 = [x[0] for x in x_train]\n",
    "x2 = [x[1] for x in x_train]\n",
    "\n",
    "colors = [int(y[0] % 2) for y in y_train]\n",
    "plt.scatter(x1,x2, c=colors , marker='^')\n",
    "\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Tensorflow Eager\n",
    "### 위 Data를 기준으로 XOR처리를 위한 모델을 만들도록 하겠습니다\n",
    "* Tensorflow data API를 통해 학습시킬 값들을 담는다 (Batch Size는 한번에 학습시킬 Size로 정한다)\n",
    "* features,labels는 실재 학습에 쓰일 Data (연산을 위해 Type를 맞춰준다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((None, 2), (None, 1)), types: (tf.float32, tf.float32)>\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(len(x_train))#.repeat()\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 위 Data를 기준으로 가설의 검증을 통해 XOR처리를 위한 모델을 만들도록 하겠습니다\n",
    "* W와 b은 학습을 통해 생성되는 모델에 쓰이는 Wegith와 Bias (초기값을 variable : 0이나 Random값으로 가능 tf.random_normal([2, 1]) )\n",
    "\n",
    "![XOR NN](./pictures/xor_nn_01.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)  # for reproducibility\n",
    "\n",
    "# 0의 값으로 변수 설정\n",
    "#W = tf.Variable(tf.zeros([2,1]), name='weight')\n",
    "#b = tf.Variable(tf.zeros([1]), name='bias') \n",
    "# 임의의 값으로 변수 설정\n",
    "W1 = tf.Variable(tf.random.normal((2, 2))) # 2행 2열\n",
    "b1 = tf.Variable(tf.random.normal((2,)))\n",
    "\n",
    "W2 = tf.Variable(tf.random.normal((2, 1))) # 2행 1열\n",
    "b2 = tf.Variable(tf.random.normal((1,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Hypothesis using matrix(가설 or 모델)\n",
    "### Sigmoid 함수를 활성화 함수로 설정\n",
    "* Sigmoid는 아래 그래프와 같이 0과 1의 값만을 리턴합니다 tf.sigmoid(tf.matmul(X, W) + b)와 같습니다\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "sigmoid(x) & = \\frac{1}{1+e^{-x}}  \\\\\\\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "![sigmoid](https://upload.wikimedia.org/wikipedia/commons/8/88/Logistic-curve.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가설\n",
    "def neural_net(features):\n",
    "    layer = tf.sigmoid(tf.matmul(features, W1) + b1)\n",
    "    hypothesis  = tf.sigmoid(tf.matmul(layer, W2) + b2)\n",
    "    return hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Cost Function (손실 함수)\n",
    "$$\n",
    "\\begin{align}\n",
    "cost(h(x),y) & = −log(h(x))  &  if  &  y=1 \\\\\\\\\\\n",
    "cost(h(x),y) & = -log(1−h(x))  &  if  &  y=0\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "* 위 두수식을 합치면 아래과 같습니다\n",
    "$$\n",
    "\\begin{align}\n",
    "cost(h(x),y) & = −y log(h(x))−(1−y)log(1−h(x))\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(hypothesis, labels):\n",
    "    cost = -tf.reduce_mean(labels * tf.math.log(hypothesis) + (1 - labels) * tf.math.log(1 - hypothesis))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Optimizer (Minimize Cost Function)\n",
    "### Gradient descent\n",
    "$$ W := W-\\alpha \\frac { \\partial  }{ \\partial W } cost(W) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경사 하강법\n",
    "# tf.GradientTape() 사용\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "def grad(features, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss_fn(neural_net(features), labels)\n",
    "    return tape.gradient(loss_value, [W1, W2, b1, b2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추론한 값은 0.5를 기준(Sigmoid 그래프 참조)로 0과 1의 값을 리턴합니다.\n",
    "* Sigmoid 함수를 통해 예측값이 0.5보다 크면 1을 반환하고 0.5보다 작으면 0으로 반환합니다.\n",
    "* 가설을 통해 실재 값과 비교한 정확도를 측정합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(hypothesis, labels):\n",
    "    predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, labels), dtype=tf.int32))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0, Loss: 0.6909\n",
      "Iter: 5000, Loss: 0.6448\n",
      "Iter: 10000, Loss: 0.5668\n",
      "Iter: 15000, Loss: 0.3992\n",
      "Iter: 20000, Loss: 0.2010\n",
      "Iter: 25000, Loss: 0.1143\n",
      "Iter: 30000, Loss: 0.0767\n",
      "Iter: 35000, Loss: 0.0569\n",
      "Iter: 40000, Loss: 0.0449\n",
      "Iter: 45000, Loss: 0.0369\n",
      "Iter: 50000, Loss: 0.0313\n"
     ]
    }
   ],
   "source": [
    "# 훈련 반복 횟수 설정\n",
    "epoch = 50000\n",
    "for step in range(epoch + 1):\n",
    "    for features, labels  in iter(dataset):\n",
    "        grads = grad(features, labels)\n",
    "        optimizer.apply_gradients(grads_and_vars=zip(grads,[W1, W2, b1, b2]))\n",
    "        if step % 5000 == 0:\n",
    "            print(\"Iter: {}, Loss: {:.4f}\".format(step, loss_fn(neural_net(features),labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict (예측)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train # labels, 실제값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03049443],\n",
       "       [0.9626765 ],\n",
       "       [0.9704943 ],\n",
       "       [0.0257471 ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_net(x_train).numpy() # prediction, 예측값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testset Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터에 대한 예측\n",
    "test_acc = accuracy_fn(neural_net(x_test),y_test)\n",
    "print(\"Testset Accuracy: {:.4f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
